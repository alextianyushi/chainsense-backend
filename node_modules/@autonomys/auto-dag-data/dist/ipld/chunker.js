var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __await = (this && this.__await) || function (v) { return this instanceof __await ? (this.v = v, this) : new __await(v); }
var __asyncGenerator = (this && this.__asyncGenerator) || function (thisArg, _arguments, generator) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var g = generator.apply(thisArg, _arguments || []), i, q = [];
    return i = Object.create((typeof AsyncIterator === "function" ? AsyncIterator : Object).prototype), verb("next"), verb("throw"), verb("return", awaitReturn), i[Symbol.asyncIterator] = function () { return this; }, i;
    function awaitReturn(f) { return function (v) { return Promise.resolve(v).then(f, reject); }; }
    function verb(n, f) { if (g[n]) { i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; if (f) i[n] = f(i[n]); } }
    function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }
    function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r); }
    function fulfill(value) { resume("next", value); }
    function reject(value) { resume("throw", value); }
    function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }
};
var __asyncValues = (this && this.__asyncValues) || function (o) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var m = o[Symbol.asyncIterator], i;
    return m ? m.call(o) : (o = typeof __values === "function" ? __values(o) : o[Symbol.iterator](), i = {}, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function () { return this; }, i);
    function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }
    function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }
};
import { cidOfNode } from '../cid/index.js';
import { decodeIPLDNodeData } from '../metadata/index.js';
import { stringifyMetadata } from '../utils/metadata.js';
import { fileBuilders, metadataBuilders } from './builders.js';
import { createFolderInlinkIpldNode, createFolderIpldNode } from './nodes.js';
import { chunkBuffer, encodeNode } from './utils.js';
export const DEFAULT_NODE_MAX_SIZE = 65535;
// u8 -> 1 byte (may grow in the future but unlikely further than 255)
const NODE_TYPE_SIZE = 1;
// u32 -> 4 bytes
const NODE_LINK_DEPTH_SIZE = 4;
// u64 -> 8 bytes
const NODE_SIZE_SIZE = 8;
// Limit at 255 string length (Mac Limit)
export const MAX_NAME_SIZE = 255;
const END_OF_STRING_BYTE = 1;
const NODE_NAME_SIZE = MAX_NAME_SIZE + END_OF_STRING_BYTE;
// Upload options may be amplified in the future
const NODE_UPLOAD_OPTIONS_SIZE = 100;
// Reserve 100 bytes for future use
const NODE_RESERVED_SIZE = 100;
export const NODE_METADATA_SIZE = NODE_TYPE_SIZE +
    NODE_LINK_DEPTH_SIZE +
    NODE_SIZE_SIZE +
    NODE_NAME_SIZE +
    NODE_RESERVED_SIZE +
    NODE_UPLOAD_OPTIONS_SIZE;
export const DEFAULT_MAX_CHUNK_SIZE = DEFAULT_NODE_MAX_SIZE - NODE_METADATA_SIZE;
export const LINK_SIZE_IN_BYTES = 40;
export const DEFAULT_MAX_LINK_PER_NODE = Math.floor(DEFAULT_MAX_CHUNK_SIZE / LINK_SIZE_IN_BYTES);
export const processFileToIPLDFormat = (blockstore, file, totalSize, filename, { maxNodeSize = DEFAULT_NODE_MAX_SIZE, maxLinkPerNode = DEFAULT_MAX_LINK_PER_NODE, encryption = undefined, compression = undefined, } = {
    maxNodeSize: DEFAULT_NODE_MAX_SIZE,
    maxLinkPerNode: DEFAULT_MAX_LINK_PER_NODE,
    encryption: undefined,
    compression: undefined,
}) => {
    if (filename && filename.length > MAX_NAME_SIZE) {
        throw new Error(`Filename is too long: ${filename.length} > ${MAX_NAME_SIZE}`);
    }
    return processBufferToIPLDFormat(blockstore, file, filename, totalSize, fileBuilders, {
        maxNodeSize,
        maxLinkPerNode,
        encryption,
        compression,
    });
};
export const processMetadataToIPLDFormat = (blockstore_1, metadata_1, ...args_1) => __awaiter(void 0, [blockstore_1, metadata_1, ...args_1], void 0, function* (blockstore, metadata, limits = {
    maxNodeSize: DEFAULT_NODE_MAX_SIZE,
    maxLinkPerNode: DEFAULT_MAX_LINK_PER_NODE,
}) {
    if (metadata.name && metadata.name.length > MAX_NAME_SIZE) {
        throw new Error(`Filename is too long: ${metadata.name.length} > ${MAX_NAME_SIZE}`);
    }
    const buffer = Buffer.from(stringifyMetadata(metadata));
    return processBufferToIPLDFormat(blockstore, (function () {
        return __asyncGenerator(this, arguments, function* () {
            yield yield __await(buffer);
        });
    })(), metadata.name, BigInt(buffer.byteLength), metadataBuilders, limits);
});
const processBufferToIPLDFormat = (blockstore_1, buffer_1, filename_1, totalSize_1, builders_1, ...args_1) => __awaiter(void 0, [blockstore_1, buffer_1, filename_1, totalSize_1, builders_1, ...args_1], void 0, function* (blockstore, buffer, filename, totalSize, builders, { maxNodeSize: maxNodeSize = DEFAULT_NODE_MAX_SIZE, maxLinkPerNode = DEFAULT_MAX_LINK_PER_NODE, encryption = undefined, compression = undefined, } = {
    maxNodeSize: DEFAULT_NODE_MAX_SIZE,
    maxLinkPerNode: DEFAULT_MAX_LINK_PER_NODE,
    encryption: undefined,
    compression: undefined,
}) {
    var _a, e_1, _b, _c;
    if (filename && filename.length > MAX_NAME_SIZE) {
        throw new Error(`Filename is too long: ${filename.length} > ${MAX_NAME_SIZE}`);
    }
    const bufferChunks = chunkBuffer(buffer, { maxChunkSize: maxNodeSize - NODE_METADATA_SIZE });
    let CIDs = [];
    try {
        for (var _d = true, bufferChunks_1 = __asyncValues(bufferChunks), bufferChunks_1_1; bufferChunks_1_1 = yield bufferChunks_1.next(), _a = bufferChunks_1_1.done, !_a; _d = true) {
            _c = bufferChunks_1_1.value;
            _d = false;
            const chunk = _c;
            const node = builders.chunk(chunk);
            const cid = cidOfNode(node);
            yield blockstore.put(cid, encodeNode(node));
            CIDs.push(cid);
        }
    }
    catch (e_1_1) { e_1 = { error: e_1_1 }; }
    finally {
        try {
            if (!_d && !_a && (_b = bufferChunks_1.return)) yield _b.call(bufferChunks_1);
        }
        finally { if (e_1) throw e_1.error; }
    }
    return processBufferToIPLDFormatFromChunks(blockstore, CIDs, filename, totalSize, builders, {
        maxLinkPerNode,
        maxNodeSize,
        encryption,
        compression,
    });
});
export const processBufferToIPLDFormatFromChunks = (blockstore_1, chunks_1, filename_1, totalSize_1, builders_1, ...args_1) => __awaiter(void 0, [blockstore_1, chunks_1, filename_1, totalSize_1, builders_1, ...args_1], void 0, function* (blockstore, chunks, filename, totalSize, builders, { maxNodeSize: maxNodeSize = DEFAULT_NODE_MAX_SIZE, maxLinkPerNode = DEFAULT_MAX_LINK_PER_NODE, encryption = undefined, compression = undefined, } = {
    maxNodeSize: DEFAULT_NODE_MAX_SIZE,
    maxLinkPerNode: DEFAULT_MAX_LINK_PER_NODE,
    encryption: undefined,
    compression: undefined,
}) {
    var _a, chunks_2, chunks_2_1;
    var _b, e_2, _c, _d;
    if (filename && filename.length > MAX_NAME_SIZE) {
        throw new Error(`Filename is too long: ${filename.length} > ${MAX_NAME_SIZE}`);
    }
    let chunkCount = 0;
    let CIDs = [];
    try {
        for (_a = true, chunks_2 = __asyncValues(chunks); chunks_2_1 = yield chunks_2.next(), _b = chunks_2_1.done, !_b; _a = true) {
            _d = chunks_2_1.value;
            _a = false;
            const chunk = _d;
            CIDs.push(chunk);
            chunkCount++;
        }
    }
    catch (e_2_1) { e_2 = { error: e_2_1 }; }
    finally {
        try {
            if (!_a && !_b && (_c = chunks_2.return)) yield _c.call(chunks_2);
        }
        finally { if (e_2) throw e_2.error; }
    }
    if (CIDs.length === 1) {
        const nodeBytes = yield blockstore.get(CIDs[0]);
        yield blockstore.delete(CIDs[0]);
        const data = decodeIPLDNodeData(nodeBytes);
        const singleNode = builders.single(Buffer.from(data.data), filename, {
            compression,
            encryption,
        });
        yield blockstore.put(cidOfNode(singleNode), encodeNode(singleNode));
        const headCID = cidOfNode(singleNode);
        return headCID;
    }
    let depth = 1;
    while (CIDs.length > maxLinkPerNode) {
        const newCIDs = [];
        for (let i = 0; i < CIDs.length; i += maxLinkPerNode) {
            const chunk = CIDs.slice(i, i + maxLinkPerNode);
            const node = builders.inlink(chunk, chunk.length, depth, maxNodeSize);
            const cid = cidOfNode(node);
            yield blockstore.put(cid, encodeNode(node));
            newCIDs.push(cid);
        }
        depth++;
        CIDs = newCIDs;
    }
    const head = builders.root(CIDs, totalSize, depth, filename, maxNodeSize, {
        compression,
        encryption,
    });
    const headCID = cidOfNode(head);
    yield blockstore.put(headCID, encodeNode(head));
    return headCID;
});
export const processFolderToIPLDFormat = (blockstore_1, children_1, name_1, size_1, ...args_1) => __awaiter(void 0, [blockstore_1, children_1, name_1, size_1, ...args_1], void 0, function* (blockstore, children, name, size, { maxLinkPerNode = DEFAULT_MAX_LINK_PER_NODE, maxNodeSize: maxNodeSize = DEFAULT_NODE_MAX_SIZE, compression = undefined, encryption = undefined, } = {
    maxLinkPerNode: DEFAULT_MAX_LINK_PER_NODE,
    maxNodeSize: DEFAULT_NODE_MAX_SIZE,
    compression: undefined,
    encryption: undefined,
}) {
    if (name.length > MAX_NAME_SIZE) {
        throw new Error(`Filename is too long: ${name.length} > ${MAX_NAME_SIZE}`);
    }
    let cids = children;
    let depth = 0;
    while (cids.length > maxLinkPerNode) {
        const newCIDs = [];
        for (let i = 0; i < cids.length; i += maxLinkPerNode) {
            const chunk = cids.slice(i, i + maxLinkPerNode);
            const node = createFolderInlinkIpldNode(chunk, depth);
            const cid = cidOfNode(node);
            yield blockstore.put(cid, encodeNode(node));
            newCIDs.push(cid);
        }
        cids = newCIDs;
        depth++;
    }
    const node = createFolderIpldNode(cids, name, depth, size, maxNodeSize, {
        compression,
        encryption,
    });
    const cid = cidOfNode(node);
    yield blockstore.put(cid, encodeNode(node));
    return cid;
});
/**
 * Process chunks to IPLD format, return the last chunk if it's not full
 * @returns the last chunk if it's not full, otherwise an empty buffer
 */
export const processChunksToIPLDFormat = (blockstore_1, chunks_1, builders_1, ...args_1) => __awaiter(void 0, [blockstore_1, chunks_1, builders_1, ...args_1], void 0, function* (blockstore, chunks, builders, { maxChunkSize = DEFAULT_MAX_CHUNK_SIZE } = {
    maxChunkSize: DEFAULT_MAX_CHUNK_SIZE,
}) {
    var _a, e_3, _b, _c;
    const bufferChunks = chunkBuffer(chunks, {
        maxChunkSize,
        ignoreLastChunk: false,
    });
    try {
        for (var _d = true, bufferChunks_2 = __asyncValues(bufferChunks), bufferChunks_2_1; bufferChunks_2_1 = yield bufferChunks_2.next(), _a = bufferChunks_2_1.done, !_a; _d = true) {
            _c = bufferChunks_2_1.value;
            _d = false;
            const chunk = _c;
            if (chunk.byteLength < maxChunkSize) {
                return chunk;
            }
            const node = builders.chunk(chunk);
            const cid = cidOfNode(node);
            yield blockstore.put(cid, encodeNode(node));
        }
    }
    catch (e_3_1) { e_3 = { error: e_3_1 }; }
    finally {
        try {
            if (!_d && !_a && (_b = bufferChunks_2.return)) yield _b.call(bufferChunks_2);
        }
        finally { if (e_3) throw e_3.error; }
    }
    return Buffer.alloc(0);
});
export const ensureNodeMaxSize = (node, maxSize = DEFAULT_NODE_MAX_SIZE) => {
    const nodeSize = encodeNode(node).byteLength;
    if (nodeSize > maxSize) {
        throw new Error(`Node is too large to fit in a single chunk: ${nodeSize} > ${maxSize}`);
    }
    return node;
};
